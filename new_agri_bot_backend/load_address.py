import csv
from collections import defaultdict
import asyncio
from typing import Optional

from piccolo.query import Insert

from new_agri_bot_backend.tables import AddressGuide
from new_agri_bot_backend.config import logger


def _get_pk_code(row: dict) -> Optional[str]:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–æ–¥ (Primary Key) –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–æ–∫–∏,
    –≤—ã–±–∏—Ä–∞—è –∫–æ–¥ —Å–∞–º–æ–≥–æ –Ω–∏–∑–∫–æ–≥–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è.
    """
    if row.get("level_5_id"):
        return row["level_5_id"]
    if row.get("level_4_id"):
        return row["level_4_id"]
    if row.get("level_3_id"):
        return row["level_3_id"]
    if row.get("level_2_id"):
        return row["level_2_id"]
    if row.get("level_1_id"):
        return row["level_1_id"]
    return None


async def load_address_guide_data(csv_filepath: str):
    """
    –ß–∏—Ç–∞–µ—Ç CSV, —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ –∏–µ—Ä–∞—Ä—Ö–∏–∏ –∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –º–∞—Å—Å–æ–≤—É—é –≤—Å—Ç–∞–≤–∫—É.
    """
    # ‚ö†Ô∏è –í–ê–ñ–ù–û: –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —ç—Ç–æ—Ç —Å–ø–∏—Å–æ–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ø–æ—Ä—è–¥–∫—É –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏!
    LOAD_ORDER = ["O", "K", "P", "H", "M", "X", "C", "B"]
    
    grouped_data = defaultdict(list)

    try:
        # 1. –ß—Ç–µ–Ω–∏–µ CSV, –æ—á–∏—Å—Ç–∫–∞ –∏ –¥–µ—Ä–∏–≤–∞—Ü–∏—è Primary Key
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º 'utf-8-sig', —á—Ç–æ–±—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å BOM-—Å–∏–º–≤–æ–ª (\ufeff) –≤ –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞.
        with open(csv_filepath, "r", encoding="utf-8-sig") as f:
            # DictReader –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–∫–∏ (–∫–ª—é—á–∏ —Å–ª–æ–≤–∞—Ä—è).
            reader = csv.DictReader(f, delimiter=';')

            for row in reader:
                # –û—á–∏—â–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤.
                cleaned_row = {k: v.strip() if v else None for k, v in row.items()}

                # --- –í–´–ß–ò–°–õ–ï–ù–ò–ï –£–ù–ò–ö–ê–õ–¨–ù–û–ì–û –ö–û–î–ê (PK) ---
                pk_code = _get_pk_code(cleaned_row)

                if not pk_code:
                    # –ï—Å–ª–∏ –¥–ª—è —Å—Ç—Ä–æ–∫–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–æ–¥, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –µ–µ.
                    # (–≠—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–æ–∏–∑–æ–π—Ç–∏ –¥–ª—è –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –≤ –∫–æ–Ω—Ü–µ —Ñ–∞–π–ª–∞)
                    continue

                # –ï—Å–ª–∏ pk_code –Ω–∞–π–¥–µ–Ω, –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –µ–≥–æ –∏ –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫—É –≤ –Ω—É–∂–Ω—É—é –≥—Ä—É–ø–ø—É.
                cleaned_row["id"] = pk_code
                category = cleaned_row.get("category")

                if category and category in LOAD_ORDER:
                    grouped_data[category].append(cleaned_row)

    except FileNotFoundError:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª '{csv_filepath}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è CSV: {e}")
        return

    # 2. –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–¥–ª—è —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–∏—è FK)
    for category in LOAD_ORDER:
        rows_to_insert = grouped_data.get(category, [])
        if not rows_to_insert:
            continue

        logger.info(f"--- –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}' ({len(rows_to_insert)} –∑–∞–ø–∏—Å–µ–π)...")

        try:
            # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤ –º–æ–¥–µ–ª–∏ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ —Å–ª–æ–≤–∞—Ä–µ–π.
            models_to_insert = [
                AddressGuide(**row)
                for row in rows_to_insert
            ]

            # 3. –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ—Å—Ç—É—é –º–∞—Å—Å–æ–≤—É—é –≤—Å—Ç–∞–≤–∫—É –ü–ê–ö–ï–¢–ê–ú–ò.
            # ‚ö†Ô∏è –ü–†–ï–î–ü–û–õ–ê–ì–ê–ï–¢–°–Ø, –ß–¢–û –¢–ê–ë–õ–ò–¶–ê –ë–´–õ–ê –û–ß–ò–©–ï–ù–ê –í–†–£–ß–ù–£–Æ –ü–ï–†–ï–î –ó–ê–ü–£–°–ö–û–ú.
            BATCH_SIZE = 1000

            for i in range(0, len(models_to_insert), BATCH_SIZE):
                # –ë–µ—Ä–µ–º "—Å—Ä–µ–∑" –¥–∞–Ω–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–º BATCH_SIZE
                batch = models_to_insert[i : i + BATCH_SIZE]
                # –í—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —ç—Ç–æ—Ç –ø–∞–∫–µ—Ç
                await AddressGuide.insert(*batch).run()

            logger.info(
                f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(rows_to_insert)} –∑–∞–ø–∏—Å–µ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'."
            )

        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}: {e}")
            logger.error(
                "‚ùó –ü—Ä–æ—Ü–µ—Å—Å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã."
            )
            return


# ----------------------------------------------------

if __name__ == "__main__":
    # ‚ö†Ô∏è –ó–ê–ú–ï–ù–ò–¢–ï –≠–¢–£ –°–¢–†–û–ö–£ –ù–ê –ê–ö–¢–£–ê–õ–¨–ù–´–ô –ü–£–¢–¨ –ö –í–ê–®–ï–ú–£ –§–ê–ô–õ–£
    CSV_FILE_PATH = "../–ö–Ω–∏–≥–∞1.csv"

    import asyncio, os, sys

    # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞, —á—Ç–æ–±—ã –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å piccolo_conf
    sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
    from piccolo_conf import DB

    # –ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ:
    # 1. –¢–∞–±–ª–∏—Ü–∞ AddressGuide —Å–æ–∑–¥–∞–Ω–∞ –º–∏–≥—Ä–∞—Ü–∏–µ–π.
    # 2. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö Piccolo –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞.

    async def run_main():
        try:
            await DB.start_connection_pool()
            await load_address_guide_data(CSV_FILE_PATH)
        finally:
            await DB.close_connection_pool()

    asyncio.run(run_main())
    logger.info("\nüèÅ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
