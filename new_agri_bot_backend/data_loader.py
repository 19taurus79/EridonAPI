# app/data_loader.py
import asyncio
import csv
import uuid
import json
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor
import pandas as pd
import numpy as np
import re
from typing import Dict, Any, Tuple, List, Optional

from piccolo.query import Insert

from .config import bot, ADMINS_ID, logger
from .services.ordered_moved_notifications import notifications
from .services.send_telegram_notification import send_notification

# from piccolo_conf import DB

# –ò–º–ø–æ—Ä—Ç—ã –º–æ–¥–µ–ª–µ–π Piccolo ORM
from .tables import (
    AvailableStock,
    Remains,
    Submissions,
    Payment,
    MovedData,
    ProductGuide,
    FreeStock,
    AddressGuide,
)

# –ò–º–ø–æ—Ä—Ç—ã —Ñ—É–Ω–∫—Ü–∏–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
from .data_processing import (
    process_av_stock,
    process_remains_reg,
    process_submissions,
    process_payment,
    process_moved_data,
    process_free_stock,
    process_moved_raw_data,
    process_ordered_raw_data,
)

# –ü—É–ª –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π Pandas
executor = ThreadPoolExecutor(max_workers=4)


async def run_in_threadpool(func, *args):
    """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ."""
    loop = asyncio.get_running_loop()
    return await loop.run_in_executor(executor, func, *args)


# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Ç–∏–ø–æ–≤ ---


def convert_numpy_types(data):
    """
    –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ö–æ–¥–∏—Ç –≤–ª–æ–∂–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞—Ä–∏ –∏ —Å–ø–∏—Å–∫–∏, –ø—Ä–µ–æ–±—Ä–∞–∑—É—è —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö NumPy
    (–Ω–∞–ø—Ä–∏–º–µ—Ä, numpy.int64) –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ç–∏–ø—ã Python (int, float).
    –≠—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ, —á—Ç–æ–±—ã Pydantic –º–æ–≥ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ JSON.
    """
    if isinstance(data, dict):
        return {k: convert_numpy_types(v) for k, v in data.items()}
    if isinstance(data, list):
        return [convert_numpy_types(i) for i in data]
    if isinstance(data, np.integer):
        return int(data)
    if isinstance(data, np.floating):
        return float(data)
    if isinstance(data, np.ndarray):
        return data.tolist()
    return data


async def save_processed_data_to_db(
    av_stock_content: bytes,
    remains_content: bytes,
    submissions_content: bytes,
    payment_content: bytes,
    # moved_content: bytes,
    free_stock_content: bytes,
    manual_matches_json: str = None,
):
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.
    –û—Ä–∫–µ—Å—Ç—Ä–∏—Ä—É–µ—Ç –≤—ã–∑–æ–≤—ã —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π —Å –ë–î.
    """
    log_messages = []

    def log(message):
        logger.info(message)
        log_messages.append(message)

    log("üöÄ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö...")

    # 1. –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ Excel-—Ñ–∞–π–ª–æ–≤ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–≤–µ
    df_av_stock = await run_in_threadpool(process_av_stock, av_stock_content)
    df_remains = await run_in_threadpool(process_remains_reg, remains_content)
    df_submissions = await run_in_threadpool(process_submissions, submissions_content)
    df_payment = await run_in_threadpool(process_payment, payment_content)
    # df_moved = await run_in_threadpool(process_moved_data, moved_content)
    df_free_stock = await run_in_threadpool(process_free_stock, free_stock_content)

    # --- –ì–õ–û–ë–ê–õ–¨–ù–ê–Ø –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø: –û—á–∏—â–∞–µ–º 'product' –≤–æ –≤—Å–µ—Ö DataFrame ---
    # --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø–æ–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤ float –¥–ª—è df_free_stock ---
    for col in ["free_qty", "buh_qty", "skl_qty"]:
        if col in df_free_stock.columns:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —á–∏—Å–ª–æ–≤–æ–π —Ç–∏–ø, –Ω–µ—á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å—Ç–∞–Ω—É—Ç NaN, –∑–∞—Ç–µ–º –∑–∞–º–µ–Ω—è–µ–º NaN –Ω–∞ 0.0
            df_free_stock[col] = pd.to_numeric(df_free_stock[col], errors='coerce').fillna(0.0).astype(float)
    # ---------------------------------------------------------------------

    df_av_stock["product"] = df_av_stock["product"].str.strip()
    df_remains["product"] = df_remains["product"].str.strip()
    df_submissions["product"] = df_submissions["product"].str.strip()
    # df_moved["product"] = df_moved["product"].str.strip()
    df_free_stock["product"] = df_free_stock["product"].str.strip()

    log("‚úÖ –î–∞–Ω–Ω—ã–µ Excel –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã. –ù–∞—á–∏–Ω–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î...")

    # 2.1 –°–æ–∑–¥–∞–Ω–∏–µ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤
    av_stock_tmp = df_av_stock[["product", "line_of_business", "active_substance"]]
    remains_tmp = df_remains[["product", "line_of_business", "active_substance"]]
    submissions_tmp = df_submissions[
        ["product", "line_of_business", "active_ingredient"]
    ].rename(columns={"active_ingredient": "active_substance"})
    pr = pd.concat([av_stock_tmp, submissions_tmp, remains_tmp], ignore_index=True)
    product_guide = pr.drop_duplicates(["product"]).reset_index(drop=True)

    product_guide["product"] = product_guide["product"].str.strip()
    product_guide.insert(0, "id", product_guide.apply(lambda _: uuid.uuid4(), axis=1))

    BATCH_SIZE = 1000
    if not product_guide.empty:
        try:
            await ProductGuide.delete(force=True).run()
            records_product_guide = product_guide.to_dict(orient="records")
            product_guide_raw = [ProductGuide(**item) for item in records_product_guide]
            for i in range(0, len(product_guide_raw), BATCH_SIZE):
                batch = product_guide_raw[i : i + BATCH_SIZE]
                await ProductGuide.insert().add(*list(batch)).run()
            log(f"üì¶ –í—Å—Ç–∞–≤–ª–µ–Ω–æ {len(records_product_guide)} –∑–∞–ø–∏—Å–µ–π –≤ ProductGuide.")
        except Exception as e:
            log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –≤ ProductGuide: {e}")

    if not df_av_stock.empty:
        try:
            df_av_stock = df_av_stock.drop("active_substance", axis=1)
            await AvailableStock.delete(force=True).run()
            av_stock_data = df_av_stock.merge(
                product_guide, on="product", how="left", suffixes=("_av", "_guide")
            )
            av_stock_data = av_stock_data.drop(
                ["product", "line_of_business_guide", "active_substance"], axis=1
            )
            av_stock_data = av_stock_data.rename(columns={"id": "product"})
            av_stock_data = av_stock_data.rename(
                columns={"line_of_business_av": "line_of_business"}
            )

            records_av_stock = av_stock_data.to_dict(orient="records")
            av_stock_raw = [AvailableStock(**item) for item in records_av_stock]

            for i in range(0, len(av_stock_raw), BATCH_SIZE):
                batch = av_stock_raw[i : i + BATCH_SIZE]
                await AvailableStock.insert().add(*list(batch)).run()
            log(f"üìâ –í—Å—Ç–∞–≤–ª–µ–Ω–æ {len(records_av_stock)} –∑–∞–ø–∏—Å–µ–π –≤ AvailableStock.")
        except Exception as e:
            log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –≤ AvailableStock: {e}")
    else:
        log("‚ö†Ô∏è DataFrame –¥–ª—è AvailableStock –ø—É—Å—Ç.")

    if not df_remains.empty:
        try:
            await Remains.delete(force=True).run()
            remains_data = df_remains.merge(
                product_guide, on="product", how="left", suffixes=("_av", "_guide")
            )
            remains_data = remains_data.drop(
                ["product", "line_of_business_guide", "active_substance_guide"], axis=1
            )
            remains_data = remains_data.rename(columns={"id": "product"})
            remains_data = remains_data.rename(
                columns={"active_substance_av": "active_substance"}
            )
            remains_data = remains_data.rename(
                columns={"line_of_business_av": "line_of_business"}
            )
            records_remains = remains_data.to_dict(orient="records")
            remains_raw = [Remains(**item) for item in records_remains]
            for i in range(0, len(remains_raw), BATCH_SIZE):
                batch = remains_raw[i : i + BATCH_SIZE]
                await Remains.insert().add(*list(batch)).run()
            log(f"üè† –í—Å—Ç–∞–≤–ª–µ–Ω–æ {len(records_remains)} –∑–∞–ø–∏—Å–µ–π –≤ Remains.")
        except Exception as e:
            log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –≤ Remains: {e}")
    else:
        log("‚ö†Ô∏è DataFrame –¥–ª—è Remains –ø—É—Å—Ç.")

    if not df_submissions.empty:
        try:
            await Submissions.delete(force=True).run()
            submissions_data = df_submissions.merge(
                product_guide, on="product", how="left", suffixes=("_av", "_guide")
            )
            submissions_data = submissions_data.drop(
                ["product", "line_of_business_guide", "active_substance"], axis=1
            )
            submissions_data = submissions_data.rename(columns={"id": "product"})
            submissions_data = submissions_data.rename(
                columns={"line_of_business_av": "line_of_business"}
            )
            df_submissions["client"] = df_submissions["client"].str.strip()
            df_payment["client"] = df_payment["client"].str.strip()
            df_payment["contract_supplement"] = (
                df_payment["contract_supplement"].str.strip()
            )
            df_submissions["contract_supplement"] = (
                df_submissions["contract_supplement"].str.strip()
            )
            submissions_data = pd.merge(
                submissions_data,
                df_payment[["client", "contract_supplement", "order_status"]],
                how="left",
                on=["client", "contract_supplement"],
            )
            submissions_data.drop(columns="delivery_status", inplace=True)
            submissions_data = submissions_data.rename(
                columns={"order_status": "delivery_status"}
            )

            submissions_data["delivery_status"] = submissions_data[
                "delivery_status"
            ].fillna("–ù—ñ")
            records_submissions = submissions_data.to_dict(orient="records")
            submissions_raw = [Submissions(**item) for item in records_submissions]
            for i in range(0, len(submissions_raw), BATCH_SIZE):
                batch = submissions_raw[i : i + BATCH_SIZE]
                await Submissions.insert().add(*list(batch)).run()
            log(f"üìë –í—Å—Ç–∞–≤–ª–µ–Ω–æ {len(records_submissions)} –∑–∞–ø–∏—Å–µ–π –≤ Submissions.")
        except Exception as e:
            log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –≤ Submissions: {e}")
    else:
        log("‚ö†Ô∏è DataFrame –¥–ª—è Submissions –ø—É—Å—Ç.")

    if not df_payment.empty:
        try:
            await Payment.delete(force=True).run()
            df_payment_for_db = df_payment
            records_payment = df_payment_for_db.to_dict(orient="records")
            payment_raw = [Payment(**item) for item in records_payment]
            for i in range(0, len(payment_raw), BATCH_SIZE):
                batch = payment_raw[i : i + BATCH_SIZE]
                await Payment.insert().add(*list(batch)).run()
            log(f"üí≥ –í—Å—Ç–∞–≤–ª–µ–Ω–æ {len(records_payment)} –∑–∞–ø–∏—Å–µ–π –≤ Payment.")
        except Exception as e:
            log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –≤ Payment: {e}")
    else:
        log("‚ö†Ô∏è DataFrame –¥–ª—è Payment –ø—É—Å—Ç.")
        
    moved = await MovedData.select().run()
    df_moved = pd.DataFrame(moved)
    df_moved = pd.merge(
        product_guide[["product", "id"]],
        df_moved,
        on="product",
        suffixes=["guide", "moved"],
    )
    df_moved["product_id"] = df_moved["idguide"]
    df_moved["product_id"] = df_moved["product_id"].astype(str)
    df_moved = df_moved.drop(columns=["idguide", "idmoved"])
    if not df_moved.empty:
        try:
            await MovedData.delete(force=True).run()
            # moved_data = df_moved.merge(
            #     product_guide, on="product", how="left", suffixes=("_av", "_guide")
            # )
            # moved_data["id"] = moved_data["id"].astype(str)
            # moved_data = moved_data.drop(
            #     ["line_of_business_guide", "active_substance"], axis=1
            # )
            # moved_data = moved_data.rename(
            #     columns={"line_of_business_av": "line_of_business"}
            # )
            # moved_data = moved_data.rename(columns={"id": "product_id"})
            moved_data = df_moved.copy()
            records_moved = moved_data.to_dict(orient="records")
            moved_raw = [MovedData(**item) for item in records_moved]
            for i in range(0, len(moved_raw), BATCH_SIZE):
                batch = moved_raw[i : i + BATCH_SIZE]
                await MovedData.insert().add(*list(batch)).run()
            log(f"üöö –í—Å—Ç–∞–≤–ª–µ–Ω–æ {len(records_moved)} –∑–∞–ø–∏—Å–µ–π –≤ MovedData.")
        except Exception as e:
            log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –≤ MovedData: {e}")
    else:
        log("‚ö†Ô∏è DataFrame –¥–ª—è MovedData –ø—É—Å—Ç.")

    if not df_free_stock.empty:
        try:
            await FreeStock.delete(force=True).run()
            free_stock_data = df_free_stock.merge(
                product_guide, on="product", how="left", suffixes=("_av", "_guide")
            )
            free_stock_data = free_stock_data.drop(
                ["product", "line_of_business_guide", "active_substance"], axis=1
            )
            free_stock_data = free_stock_data.rename(columns={"id_guide": "product"})
            free_stock_data = free_stock_data.rename(columns={"id_av": "id"})
            free_stock_data = free_stock_data.rename(
                columns={"line_of_business_av": "line_of_business"}
            )
            free_stock_data.dropna(subset=["product"], inplace=True)

            records_free_stock = free_stock_data.to_dict(orient="records")
            free_stock_raw = [FreeStock(**item) for item in records_free_stock]

            for i in range(0, len(free_stock_raw), BATCH_SIZE):
                batch = free_stock_raw[i : i + BATCH_SIZE]
                await FreeStock.insert().add(*list(batch)).run()

            log(f"üì¶ –í—Å—Ç–∞–≤–ª–µ–Ω–æ {len(records_free_stock)} –∑–∞–ø–∏—Å–µ–π –≤ FreeStock.")
        except Exception as e:
            log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –≤ FreeStock: {e}")
    else:
        log("‚ö†Ô∏è DataFrame –¥–ª—è FreeStock –ø—É—Å—Ç.")

    df_manual_matches = pd.DataFrame()
    if manual_matches_json:
        try:
            manual_matches_list = json.loads(manual_matches_json)
            if manual_matches_list:
                df_manual_matches = pd.DataFrame(
                    manual_matches_list.get("matched_data")
                    or manual_matches_list.get("matched_list", [])
                )
                if "–î–∞—Ç–∞" in df_manual_matches.columns:
                    df_manual_matches["–î–∞—Ç–∞"] = pd.to_datetime(
                        df_manual_matches["–î–∞—Ç–∞"], errors="coerce"
                    )
                log(
                    f"ü§ù –°–æ–∑–¥–∞–Ω DataFrame 'df_manual_matches' –∏–∑ —Ä—É—á–Ω—ã—Ö —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–π, —Ä–∞–∑–º–µ—Ä: {df_manual_matches.shape}."
                )
        except (json.JSONDecodeError, AttributeError) as e:
            log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ JSON –∏–∑ manual_matches_json: {e}")

    if not df_manual_matches.empty:
        try:
            columns_to_delete = [
                "–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞",
                "–û–∑–Ω–∞–∫–∞ –ø–∞—Ä—Ç—ñ—ó",
                "–°–µ–∑–æ–Ω –∑–∞–∫—É–ø—ñ–≤–ª—ñ",
                "–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ_–∑–∞–∫–∞–∑–∞–Ω–æ",
                "–ü–µ—Ä–µ–º–µ—â–µ–Ω–æ",
                "–ò—Å—Ç–æ—á–Ω–∏–∫",
            ]
            df_matches = df_manual_matches.drop(
                columns=columns_to_delete, errors="ignore"
            )

            rename_map = {
                "–ó–∞—è–≤–∫–∞ –Ω–∞ –≤—ñ–¥–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è": "order",
                "–ó–∞–∫–∞–∑–∞–Ω–æ": "qt_order",
                "–†—ñ–∫ –¥–æ–≥–æ–≤–æ—Ä—É": "period",
                "–ü–∞—Ä—Ç—ñ—è –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∏": "party_sign",
                "–í–∏–¥ –¥—ñ—è–ª—å–Ω–æ—Å—Ç—ñ": "line_of_business",
                "–î–∞—Ç–∞": "date",
                "–¢–æ–≤–∞—Ä": "product",
                "–î–æ–≥–æ–≤–æ—Ä": "contract",
                "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ": "qt_moved",
            }
            df_matches = df_matches.rename(columns=rename_map)

            for col in ["product", "contract", "period"]:
                if col in df_matches.columns:
                    df_matches[col] = df_matches[col].astype(str).str.strip()

            df_matches["product"] = df_matches["product"].str.strip()

            product_id_map = product_guide.set_index("product")["id"]
            df_matches["product_id"] = df_matches["product"].map(product_id_map)

            # --- –û–ë–ù–û–í–õ–ï–ù–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –î–£–ë–õ–ò–ö–ê–¢–û–í ---
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –ø–æ–ª–µ–π –¥–ª—è —Ç–æ—á–Ω–æ–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∑–∞–ø–∏—Å–∏
            existing_moved_data_list = await MovedData.select(
                MovedData.product_id, 
                MovedData.order, 
                MovedData.party_sign, 
                MovedData.qt_moved, 
                MovedData.date
            ).run()
            df_moved_from_db = pd.DataFrame(existing_moved_data_list)

            df_new_matches_to_add = pd.DataFrame()

            # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∫–ª—é—á–∞ (–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö)
            def create_key(row):
                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ (100.0 -> "100")
                q = row.get("qt_moved")
                try:
                    q_val = float(q)
                    q_str = f"{q_val:g}"
                except (ValueError, TypeError):
                    q_str = str(q) if pd.notna(q) else ""
                
                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞—Ç—ã
                d = row.get("date")
                d_str = str(d).split(" ")[0] if pd.notna(d) else ""
                
                return f"{row.get('product_id')}_{row.get('order')}_{row.get('party_sign')}_{q_str}_{d_str}"

            if not df_moved_from_db.empty:
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–ª—é—á–∏ –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å–µ–π
                df_moved_from_db["composite_key"] = df_moved_from_db.apply(create_key, axis=1)
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–ª—é—á–∏ –¥–ª—è –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π
                # –í–∞–∂–Ω–æ: df_matches —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (order, qt_moved –∏ —Ç.–¥.)
                df_matches["composite_key"] = df_matches.apply(create_key, axis=1)

                existing_keys = set(df_moved_from_db["composite_key"])
                df_new_matches_to_add = df_matches[
                    ~df_matches["composite_key"].isin(existing_keys)
                ].copy()
                df_new_matches_to_add.drop(columns=["composite_key"], inplace=True)
            else:
                df_new_matches_to_add = df_matches.copy()

            if not df_new_matches_to_add.empty:
                log(
                    f"üîç –ù–∞–π–¥–µ–Ω–æ {len(df_new_matches_to_add)} –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ MovedData."
                )
                df_new_matches_to_add = df_new_matches_to_add.replace({np.nan: None})

                # --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ó–î–ï–°–¨ ---
                if "product_id" in df_new_matches_to_add.columns:
                    df_new_matches_to_add["product_id"] = df_new_matches_to_add[
                        "product_id"
                    ].astype(str)

                cols_to_str = ["period", "party_sign"]
                for col in cols_to_str:
                    if col in df_new_matches_to_add.columns:
                        df_new_matches_to_add[col] = df_new_matches_to_add[col].apply(
                            lambda x: (
                                str(int(x))
                                if pd.notna(x) and isinstance(x, (int, float, np.integer, np.floating))
                                else (str(x) if pd.notna(x) else None)
                            )
                        )

                records_to_add = df_new_matches_to_add.to_dict(orient="records")

                valid_columns = MovedData._meta.columns
                cleaned_records = [
                    {k: v for k, v in rec.items() if k in valid_columns}
                    for rec in records_to_add
                ]

                await MovedData.insert(
                    *[MovedData(**rec) for rec in cleaned_records]
                ).run()
                log("‚úÖ –ù–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ MovedData.")
                await notifications(bot=bot, frame=df_new_matches_to_add)
            else:
                log("‚ÑπÔ∏è –ù–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ MovedData –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")

        except Exception as e:
            log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ df_manual_matches: {e}")
    else:
        log("‚ÑπÔ∏è –î–∞–Ω–Ω—ã–µ –¥–ª—è —Ä—É—á–Ω–æ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã –∏–ª–∏ DataFrame –ø—É—Å—Ç.")

    log("üèÅ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö.")

    # --- –û–¢–ü–†–ê–í–ö–ê –õ–û–ì–û–í –í TELEGRAM ---
    if ADMINS_ID:
        try:
            admin_ids = json.loads(ADMINS_ID)
            if isinstance(admin_ids, list):
                # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ç–µ–∫—Å—Ç
                full_log_text = "üìä *–û—Ç—á–µ—Ç –æ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö*\n\n" + "\n".join(log_messages)
                
                # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, aiogram –º–æ–∂–µ—Ç –≤—ã–¥–∞—Ç—å –æ—à–∏–±–∫—É, 
                # –Ω–æ –∑–¥–µ—Å—å –æ–±—ä–µ–º –æ–±—ã—á–Ω–æ –Ω–µ–±–æ–ª—å—à–æ–π. –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã —Ä–∞–∑–±–∏—Ç—å,
                # –Ω–æ –ø–æ–∫–∞ –æ—Ç–ø—Ä–∞–≤–∏–º —Ü–µ–ª–∏–∫–æ–º.
                await send_notification(
                    bot=bot,
                    chat_ids=[int(uid) for uid in admin_ids],
                    text=full_log_text,
                    parse_mode="Markdown"
                )
        except Exception as e:
            logger.error(f"!!! –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –ª–æ–≥–æ–≤ –∞–¥–º–∏–Ω–∞–º: {e}")
